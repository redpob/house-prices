{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import Pool\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dummy=pd.read_csv('train_test_dummy.csv')\n",
    "train_test=pd.read_csv('train_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SqFtPerRoom</th>\n",
       "      <th>Total_Home_Quality</th>\n",
       "      <th>Total_Bathrooms</th>\n",
       "      <th>HighQualSF</th>\n",
       "      <th>renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>139.555556</td>\n",
       "      <td>56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1256</td>\n",
       "      <td>3930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>896</td>\n",
       "      <td>3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147.666667</td>\n",
       "      <td>66</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1329</td>\n",
       "      <td>3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>162.900000</td>\n",
       "      <td>55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1629</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145.818182</td>\n",
       "      <td>66</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1604</td>\n",
       "      <td>3996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>3984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "3999        1459          20       RL         75.0     9937   Pave  None   \n",
       "4000           0          20       RH         80.0    11622   Pave  None   \n",
       "4001           1          20       RL         81.0    14267   Pave  None   \n",
       "4002           2          60       RL         74.0    13830   Pave  None   \n",
       "4003           3          60       RL         78.0     9978   Pave  None   \n",
       "4004           4         120       RL         43.0     5005   Pave  None   \n",
       "\n",
       "     LotShape LandContour Utilities  ... MiscVal MoSold YrSold SaleType  \\\n",
       "3999      Reg         Lvl    AllPub  ...       0      6   2008       WD   \n",
       "4000      Reg         Lvl    AllPub  ...       0      6   2010       WD   \n",
       "4001      IR1         Lvl    AllPub  ...   12500      6   2010       WD   \n",
       "4002      IR1         Lvl    AllPub  ...       0      3   2010       WD   \n",
       "4003      IR1         Lvl    AllPub  ...       0      6   2010       WD   \n",
       "4004      IR1         HLS    AllPub  ...       0      1   2010       WD   \n",
       "\n",
       "     SaleCondition SqFtPerRoom Total_Home_Quality  Total_Bathrooms  \\\n",
       "3999        Normal  139.555556                 56              2.5   \n",
       "4000        Normal  128.000000                 56              1.0   \n",
       "4001        Normal  147.666667                 66              1.5   \n",
       "4002        Normal  162.900000                 55              2.5   \n",
       "4003        Normal  145.818182                 66              2.5   \n",
       "4004        Normal  160.000000                 85              2.0   \n",
       "\n",
       "      HighQualSF  renovated  \n",
       "3999        1256       3930  \n",
       "4000         896       3922  \n",
       "4001        1329       3916  \n",
       "4002        1629       3995  \n",
       "4003        1604       3996  \n",
       "4004        1280       3984  \n",
       "\n",
       "[6 rows x 83 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.iloc[3999:4005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test separation\n",
    "\n",
    "X_train = train_test_dummy[0:4000]\n",
    "X_test = train_test_dummy[4000:]\n",
    "\n",
    "# Creation of the RMSE metric:\n",
    "    \n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X_train, target_log, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_log=pd.read_csv('target_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.278398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.561725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.055256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.404928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12.154258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SalePrice\n",
       "0           0  12.278398\n",
       "1           1  11.561725\n",
       "2           2  12.055256\n",
       "3           3  12.404928\n",
       "4           4  12.154258"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_log=target_log['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>Nan_sum</th>\n",
       "      <th>feat</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Serial No., Nan_sum, feat, Percentage, Perc]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nan values in training set\n",
    "nan=pd.DataFrame(X_train.isna().sum(),columns=['Nan_sum'])\n",
    "nan['feat']=nan.index\n",
    "nan=nan[nan['Nan_sum']>0]\n",
    "nan['Percentage']=(nan['Nan_sum']/1460)*100\n",
    "nan['Perc']=(nan['Nan_sum']/4000)*100\n",
    "nan=nan.sort_values(by=['Nan_sum'])\n",
    "nan.insert(0,'Serial No.',range(1,len(nan)+1))\n",
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>Nan_sum</th>\n",
       "      <th>feat</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Serial No., Nan_sum, feat, Percentage, Perc]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nan values in test set\n",
    "nan=pd.DataFrame(X_test.isna().sum(),columns=['Nan_sum'])\n",
    "nan['feat']=nan.index\n",
    "nan=nan[nan['Nan_sum']>0]\n",
    "nan['Percentage']=(nan['Nan_sum']/1460)*100\n",
    "nan['Perc']=(nan['Nan_sum']/2919)*100\n",
    "nan=nan.sort_values(by=['Nan_sum'])\n",
    "nan.insert(0,'Serial No.',range(1,len(nan)+1))\n",
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Fold Cross validation\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True) # any integer\n",
    "\n",
    "# K-Folds cross-validator: Provides train/test indices to split data in train/test sets. \n",
    "# please read the material: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "baseline_models = ['Linear_Reg.','Bayesian_Ridge_Reg.','LGBM_Reg.','SVR',\n",
    "                   'Dec_Tree_Reg.','Random_Forest_Reg.',\n",
    "                   'Grad_Boost_Reg.','Cat_Boost_Reg.','XGB_Reg.', 'ridge','lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397.234802346573\n",
      "487.286060841141\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "score_lreg = cv_rmse(lreg)\n",
    "print(score_lreg.mean())\n",
    "print(score_lreg.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id  SalePrice\n",
      "0  1461   121527.0\n",
      "1  1462   167530.0\n",
      "2  1463   183443.0\n",
      "3  1464   201251.0\n",
      "4  1465   193112.0\n"
     ]
    }
   ],
   "source": [
    "# every time you build a model, please make prediction on test dataset and make a submission.\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "lreg_model=lreg.fit(X_train,target_log)\n",
    "submission.iloc[:,1] = np.floor(np.expm1(lreg_model.predict(X_test)))\n",
    "print(submission.head())\n",
    "submission.to_csv(\"sub_lreg.csv\", index=False)  #0.11396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1178617846171008\n",
      "0.01880477771254799\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Ridge Regression\n",
    "\n",
    "brr = BayesianRidge(compute_score=True)\n",
    "score_brr = cv_rmse(brr)\n",
    "#https://scikit-learn.org/stable/auto_examples/linear_model/plot_bayesian_ridge.html\n",
    "print(score_brr.mean())\n",
    "print(score_brr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id  SalePrice\n",
      "0  1461   118189.0\n",
      "1  1462   145098.0\n",
      "2  1463   180003.0\n",
      "3  1464   198524.0\n",
      "4  1465   193294.0\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "brr_model=brr.fit(X_train,target_log)\n",
    "submission.iloc[:,1] = np.floor(np.expm1(brr_model.predict(X_test)))\n",
    "print(submission.head())\n",
    "submission.to_csv(\"sub_brr.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ridge and lasso regression, use grid search to find the best alpha value for the two regression\n",
    "# print the cv mean and std\n",
    "# make submission on test dataset, see the submission socre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Light Gradient Boost Regressor\n",
    "#https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "l_gbm = LGBMRegressor(objective='regression')\n",
    "score_l_gbm = cv_rmse(l_gbm)\n",
    "print(score_l_gbm.mean())\n",
    "print(score_l_gbm.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bayes_opt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7eb721626bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# bayesian optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bayes_opt'"
     ]
    }
   ],
   "source": [
    "# bayesian optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change values for learning rate (float), bagging_freq (any integer), bagging_seed (any integer) and feature_fraction_seed (any integer)\n",
    "# you can control init_round (any integer) and opt_round (any integer)\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=3, opt_round=17, n_folds=10, random_seed=42, n_estimators=5000, learning_rate=0.01,bagging_freq=5,bagging_seed=7,feature_fraction_seed=7):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, max_depth, bagging_fraction, feature_fraction,min_data_in_leaf):\n",
    "        params = {'objective':'regression','boosting_type': 'gbdt', 'verbose': -1,\\\n",
    "                  'num_boost_round': n_estimators, 'learning_rate':learning_rate,\n",
    "                  'bagging_freq':bagging_freq,'bagging_seed':bagging_seed, 'feature_fraction_seed':feature_fraction_seed}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['max_depth']=int(round(max_depth))\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params[\"min_data_in_leaf\"] = int(round(min_data_in_leaf))\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=False, verbose_eval=500, metrics=['rmse'],early_stopping_rounds=50)\n",
    "        return -1.0 * np.min(cv_result['rmse-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (1, 200),  # you can try different value range \n",
    "                                            'max_depth':(1,100),  # you can try different value range \n",
    "                                            'min_data_in_leaf':(1,100),  # you can try different value range \n",
    "                                            'bagging_fraction' : (0.1,0.9), # you can try different value range \n",
    "                                            'feature_fraction':(0.1,0.9)}) # you can try different value range \n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X_train, target_log, init_round=3, opt_round=17, n_folds=10, random_seed=42, n_estimators=5000, learning_rate=0.01,\n",
    "                                    bagging_freq=5,bagging_seed=7,feature_fraction_seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_gbm2 = LGBMRegressor(objective='regression',boosting_type='gbdt', verbose= -1,\\\n",
    "                      num_boost_round=5000, learning_rate=0.01,\\\n",
    "                      bagging_freq=5,bagging_seed=7, feature_fraction_seed=7,\\\n",
    "                     num_leaves=48,max_depth=65,bagging_fraction=0.9,feature_fraction=0.1,\\\n",
    "                     min_data_in_leaf=12)\n",
    "score_2_gbm = cv_rmse(l_gbm2)\n",
    "print(score_2_gbm.mean())\n",
    "print(score_2_gbm.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance for lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare score2 with score1, choose the model with lower mean for submission.\n",
    "# score 1 mean:0.09810103875246606\n",
    "# score 2 mean: 0.08162113750825215\n",
    "# score 2 is better, choose second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "l_gbm_model=l_gbm2.fit(X_train,target_log)\n",
    "submission.iloc[:,1] = np.floor(np.expm1(l_gbm_model.predict(X_test)))\n",
    "print(submission.head())\n",
    "submission.to_csv(\"l_gbm_brr.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "# https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2?gi=bad5aefbad71\n",
    "svr = SVR()\n",
    "score_svr = cv_rmse(svr)\n",
    "print(score_svr.mean())\n",
    "print(score_svr.std())\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_para_svm = [{'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4]}, \\\n",
    "                 {'C': [1, 10, 100, 1000], 'kernel': ['linear']}, \\\n",
    "                 {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm = GridSearchCV(svr, grid_para_svm, scoring = 'neg_mean_squared_error', cv=10)\n",
    "grid_search_svm.fit(X_train, target_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr2 = SVR(kernel='poly',C=1000, degree=4)\n",
    "# based on the result of grid search\n",
    "score2_svr = cv_rmse(svr2)\n",
    "print(score2_svr.mean())\n",
    "print(score2_svr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare score2 with score1, choose the model with lower mean for submission.\n",
    "# score 1:0.26649\n",
    "# score 2: 0.1686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "svr_model=svr2.fit(X_train,target_log)\n",
    "submission.iloc[:,1] = np.floor(np.expm1(svr_model.predict(X_test)))\n",
    "print(submission.head())\n",
    "submission.to_csv(\"sub_svr.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "score_dtr = cv_rmse(dtr)\n",
    "print(score_dtr.mean())\n",
    "print(score_dtr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use grid search to decide the tuning parameters for decision tree regressor\n",
    "# plot the feature importance\n",
    "# choose the best model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "score_rfr = cv_rmse(rfr)\n",
    "print(score_rfr.mean())\n",
    "print(score_rfr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use grid search to decide the tuning parameters for  Random Forest Regressor\n",
    "# plot the feature importance\n",
    "# choose the best model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost Regressor\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "score_gbr = cv_rmse(gbr)\n",
    "print(score_gbr.mean())\n",
    "print(score_gbr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use grid search to decide the tuning parameters for  Gradient Boost Regressor\n",
    "# plot the feature importance\n",
    "# choose the best model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat Boost Regressor\n",
    "\n",
    "catb = CatBoostRegressor()\n",
    "score_catb = cv_rmse(catb)\n",
    "#https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n",
    "print(score_catb.mean())\n",
    "print(score_catb.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "catb_model=catb.fit(X_train,target_log)\n",
    "submission.iloc[:,1] = np.floor(np.expm1(catb_model.predict(X_test)))\n",
    "print(submission.head())\n",
    "submission.to_csv(\"sub_catb.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Regressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "score_xgb = cv_rmse(xgb)\n",
    "print(score_xgb.mean())\n",
    "print(score_xgb.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use bayesian optimization to tune hyperparameters of xgb\n",
    "#  plot the feature importance\n",
    "# choose the best model for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange models' order based score from lowest to highest\n",
    "# arrange models' order based submission score from lowest to highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
